import streamlit as st
import re

from qdrant_client import QdrantClient

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
from qdrant_client.models import Filter, FieldCondition, MatchAny

from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab, Doc


if 'search_triggered' not in st.session_state:
    st.session_state.search_triggered = False
if 'page' not in st.session_state:
    st.session_state.page = 1
if "prev_genre" not in st.session_state:
    st.session_state.prev_genre = "–í—Å–µ –∂–∞–Ω—Ä—ã"
    


st.session_state.already_ran = True

with open('./data/stopwords/russian', 'r') as f:
    lines = [line.strip() for line in f.readlines()]
    
stop = set(lines) - {'–Ω–µ', '–Ω–∏'}

segmenter = Segmenter()
emb = NewsEmbedding()
morph_tagger = NewsMorphTagger(emb)
morph_vocab = MorphVocab()


GENRES = [
    '–§—ç–Ω—Ç–µ–∑–∏', '–†–æ–º–∞–Ω', '–§–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞', '–ú–æ–ª–æ–¥–µ–∂–Ω–∞—è –ø—Ä–æ–∑–∞',
    '–ü–æ–ø–∞–¥–∞–Ω—Ü—ã', '–≠—Ä–æ—Ç–∏–∫–∞', '–§–∞–Ω—Ñ–∏–∫', '–î–µ—Ç–µ–∫—Ç–∏–≤—ã',
    '–ü—Ä–æ–∑–∞', '–¢—Ä–∏–ª–ª–µ—Ä—ã', '–ú–∏—Å—Ç–∏–∫–∞/–£–∂–∞—Å—ã', '–†–∞–∑–Ω–æ–µ',
    '–ù–æ–Ω-—Ñ–∏–∫—à–Ω', '–ú–∏–Ω–∏'
]

COLLECTION_NAME = 'books-rec-project3'

model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}

hf = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
)


def clean_string(text):
    text = text.lower()
    text = re.sub(r'\s{1}[–∞-—è—ë]*\.\.\.$', '', text) #remove bad ending
    text = re.sub(r'<.*?>', ' ', text) # removing html-tags from text
    text = re.sub(r'http\S+|\S+@\S+', ' ', text) # removing links
    text = re.sub(r'[^–∞-—è—ë\s]', ' ', text.lower()) # remove all non-letter symbols
    cleaned_text = re.sub(r'\s+', ' ', text).strip() # remove double or more spaces
    
    return cleaned_text

def lemmantize_words(text):
    lemmas = []
    doc = Doc(text)
    doc.segment(segmenter)
    doc.tag_morph(morph_tagger)
    
    try:
        for token in doc.tokens:
            token.lemmatize(morph_vocab)
            lemmas.append(token.lemma)
                
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {text[:30]}... ‚Üí {e}")
        return ''
    
    return ' '.join(lemmas)

def filter_stop_words(text):
    words = []
    for word in text.split():
        if word in stop or len(word) < 2:
            continue
        words.append(word)
        
    return ' '.join(words)

def preprocess_string(string):
    if not isinstance(string, str) or len(string.strip()) == 0: # fool-protection
        return ''
    
    string = clean_string(string)
    string = lemmantize_words(string)
    string = filter_stop_words(string)
    
    return string




def render_navigation(num_pages, location):
    col1, col2, col3 = st.columns([1,2,1])
    with col1:
        if st.button("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", key=f"prev_{location}"):
            if st.session_state.page > 1:
                st.session_state.page -=1
    with col2:
        st.markdown(f"**–°—Ç—Ä–∞–Ω–∏—Ü–∞ {st.session_state.page} –∏–∑ {num_pages}**")
    with col3:
        if st.button("–í–ø–µ—Ä—ë–¥ ‚û°Ô∏è", key=f"next_{location}"):
            if st.session_state.page < num_pages:
                st.session_state.page += 1

def search_books(query, genre, top_k=5):
    client = QdrantClient(path='./db/qdrant_db')

    vector_store = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
        embedding=hf
    )
    
    my_filter = Filter()
    
    if genre in GENRES:
        my_filter = Filter(
            must = [
                FieldCondition(
                    key='metadata.main_genre',
                    match=MatchAny(any=[genre])
                )
            ]
        )
    
    results = vector_store.similarity_search(
        preprocess_string(query),
        filter=my_filter,
        k=top_k
    )
    
    client.close()

    return results




st.title('üìö –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ü–æ–∏—Å–∫ –ö–Ω–∏–≥')

col1, col2 = st.columns([4,1])
with col1:
    query = st.text_input(
        '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å', label_visibility='collapsed'
    )
with col2:
    if st.button('–ù–∞–π—Ç–∏'):
        st.session_state.search_triggered = True
        st.session_state.page = 1
    
genre = st.selectbox("üìö –§–∏–ª—å—Ç—Ä –ø–æ –∂–∞–Ω—Ä—É", ['–í—Å–µ –∂–∞–Ω—Ä—ã'] + GENRES)

if genre != st.session_state.prev_genre:
    st.session_state.page = 1
    st.session_state.prev_genre = genre
    
    
items_per_page = st.slider(
    '–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–Ω–∏–≥', min_value=1, max_value=10, value=5, step=1
)

if st.session_state.search_triggered:
    if query != '':
        results = search_books(query, genre, items_per_page)
    else:
        results = []
    
    st.markdown(f"üîé **–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:** {len(results)}")
    
    for idx, doc in enumerate(results):
        with st.container():
            book_col1, book_col2 = st.columns([1,4])
            with book_col1:
                st.image(doc.metadata.get('img_url', 'https://img.freepik.com/premium-vector/broken-image-icon_268104-8936.jpg'))
            with book_col2:
                st.markdown(f'**{doc.metadata.get('author', 'No author')}**')
                st.markdown(
                    f'[**{doc.metadata.get('title','No title')}**]({doc.metadata.get('book_url','No book_url')})'
                )
                st.markdown(f'{doc.metadata.get('annotation','No annotation')}')
                st.markdown(f'üìñ _–ñ–∞–Ω—Ä: {doc.metadata.get('main_genre','No main_genre')}_')
            st.markdown('---')
            