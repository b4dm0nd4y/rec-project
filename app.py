import streamlit as st
import pandas as pd
import re

from qdrant_client import QdrantClient

from sentence_transformers import SentenceTransformer
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
from qdrant_client.models import Filter, FieldCondition, MatchAny

import numpy as np
from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab, Doc
import nltk
from nltk.corpus import stopwords

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel

if 'search_triggered' not in st.session_state:
    st.session_state.search_triggered = False
if 'page' not in st.session_state:
    st.session_state.page = 1
if "prev_genre" not in st.session_state:
    st.session_state.prev_genre = "–í—Å–µ –∂–∞–Ω—Ä—ã"
    


st.session_state.already_ran = True

nltk.download('stopwords')
stop = set(stopwords.words('russian')) - {'–Ω–µ', '–Ω–∏'}

segmenter = Segmenter()
emb = NewsEmbedding()
morph_tagger = NewsMorphTagger(emb)
morph_vocab = MorphVocab()


GENRES = [
    '–§—ç–Ω—Ç–µ–∑–∏', '–†–æ–º–∞–Ω', '–§–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞', '–ú–æ–ª–æ–¥–µ–∂–Ω–∞—è –ø—Ä–æ–∑–∞',
    '–ü–æ–ø–∞–¥–∞–Ω—Ü—ã', '–≠—Ä–æ—Ç–∏–∫–∞', '–§–∞–Ω—Ñ–∏–∫', '–î–µ—Ç–µ–∫—Ç–∏–≤—ã',
    '–ü—Ä–æ–∑–∞', '–¢—Ä–∏–ª–ª–µ—Ä—ã', '–ú–∏—Å—Ç–∏–∫–∞/–£–∂–∞—Å—ã', '–†–∞–∑–Ω–æ–µ',
    '–ù–æ–Ω-—Ñ–∏–∫—à–Ω', '–ú–∏–Ω–∏'
]

COLLECTION_NAME = 'books-rec-project3'

model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}

hf = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
)


def clean_string(text):
    text = text.lower()
    text = re.sub(r'\s{1}[–∞-—è—ë]*\.\.\.$', '', text) #remove bad ending
    text = re.sub(r'<.*?>', ' ', text) # removing html-tags from text
    text = re.sub(r'http\S+|\S+@\S+', ' ', text) # removing links
    text = re.sub(r'[^–∞-—è—ë\s]', ' ', text.lower()) # remove all non-letter symbols
    cleaned_text = re.sub(r'\s+', ' ', text).strip() # remove double or more spaces
    
    return cleaned_text

def lemmantize_words(text):
    lemmas = []
    doc = Doc(text)
    doc.segment(segmenter)
    doc.tag_morph(morph_tagger)
    
    try:
        for token in doc.tokens:
            token.lemmatize(morph_vocab)
            lemmas.append(token.lemma)
                
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {text[:30]}... ‚Üí {e}")
        return ''
    
    return ' '.join(lemmas)

def filter_stop_words(text):
    words = []
    for word in text.split():
        if word in stop or len(word) < 2:
            continue
        words.append(word)
        
    return ' '.join(words)

def preprocess_string(string):
    if not isinstance(string, str) or len(string.strip()) == 0: # fool-protection
        return ''
    
    string = clean_string(string)
    string = lemmantize_words(string)
    string = filter_stop_words(string)
    
    return string




def render_navigation(num_pages, location):
    col1, col2, col3 = st.columns([1,2,1])
    with col1:
        if st.button("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", key=f"prev_{location}"):
            if st.session_state.page > 1:
                st.session_state.page -=1
    with col2:
        st.markdown(f"**–°—Ç—Ä–∞–Ω–∏—Ü–∞ {st.session_state.page} –∏–∑ {num_pages}**")
    with col3:
        if st.button("–í–ø–µ—Ä—ë–¥ ‚û°Ô∏è", key=f"next_{location}"):
            if st.session_state.page < num_pages:
                st.session_state.page += 1

def search_books(query, genre, top_k=5):
    client = QdrantClient(path='./db/qdrant_db')

    vector_store = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
        embedding=hf
    )
    
    my_filter = Filter()
    
    if genre in GENRES:
        my_filter = Filter(
            must = [
                FieldCondition(
                    key='metadata.main_genre',
                    match=MatchAny(any=[genre])
                )
            ]
        )
    
    results = vector_store.similarity_search(
        preprocess_string(query),
        filter=my_filter,
        k=3
    )
    
    client.close()

    return results




st.title('üìö –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ü–æ–∏—Å–∫ –ö–Ω–∏–≥')

col1, col2 = st.columns([4,1])
with col1:
    query = st.text_input(
        '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å', label_visibility='collapsed'
    )
with col2:
    if st.button('–ù–∞–π—Ç–∏'):
        st.session_state.search_triggered = True
        st.session_state.page = 1
    
genre = st.selectbox("üìö –§–∏–ª—å—Ç—Ä –ø–æ –∂–∞–Ω—Ä—É", ['–í—Å–µ –∂–∞–Ω—Ä—ã'] + GENRES)

if genre != st.session_state.prev_genre:
    st.session_state.page = 1
    st.session_state.prev_genre = genre
    
    
items_per_page = st.slider(
    '–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–Ω–∏–≥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ', min_value=1, max_value=10, value=5, step=1
)

if st.session_state.search_triggered:
    if query != '':
        results = search_books(query, genre)
    else:
        results = []
    total_books = len(results)
    num_pages = (total_books + items_per_page - 1) // items_per_page
    
    st.markdown(f"üîé **–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:** {total_books}")
    render_navigation(num_pages, location="top")
    
    for idx, doc in enumerate(results):
        with st.container():
            book_col1, book_col2 = st.columns([1,4])
            with book_col1:
                st.image(doc.metadata.get('img_url', 'https://img.freepik.com/premium-vector/broken-image-icon_268104-8936.jpg'))
            with book_col2:
                st.markdown(f'**{doc.metadata.get('author', 'No author')}**')
                st.markdown(
                    f'[**{doc.metadata.get('title','No title')}**]({doc.metadata.get('book_url','No book_url')})'
                )
                st.markdown(f'{doc.metadata.get('annotation','No annotation')}')
                st.markdown(f'üìñ _–ñ–∞–Ω—Ä: {doc.metadata.get('main_genre','No main_genre')}_')
            st.markdown('---')
            
    st.markdown(f"üîé **–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:** {total_books}")
    render_navigation(num_pages, location="bottom")